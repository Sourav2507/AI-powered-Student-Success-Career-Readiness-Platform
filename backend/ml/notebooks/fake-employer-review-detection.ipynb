{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T11:57:00.550521Z",
     "iopub.status.busy": "2025-11-30T11:57:00.550236Z",
     "iopub.status.idle": "2025-11-30T11:57:00.561505Z",
     "shell.execute_reply": "2025-11-30T11:57:00.560036Z",
     "shell.execute_reply.started": "2025-11-30T11:57:00.550501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset (Deceptive Opinion Spam Corpus)\n",
    "\n",
    "In this step, we load the Deceptive Opinion Spam dataset provided as a CSV file on Kaggle.  \n",
    "The dataset contains reviews labeled as:\n",
    "\n",
    "- **deceptive** — fake reviews  \n",
    "- **truthful** — real reviews  \n",
    "\n",
    "We will load the CSV, inspect its shape, check for missing values, and preview the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:59:28.787272Z",
     "iopub.status.busy": "2025-11-30T11:59:28.786880Z",
     "iopub.status.idle": "2025-11-30T11:59:28.824397Z",
     "shell.execute_reply": "2025-11-30T11:59:28.823153Z",
     "shell.execute_reply.started": "2025-11-30T11:59:28.787246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1600, 5)\n",
      "\n",
      "Columns: ['deceptive', 'hotel', 'polarity', 'source', 'text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>truthful</td>\n",
       "      <td>conrad</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>truthful</td>\n",
       "      <td>omni</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deceptive   hotel  polarity       source  \\\n",
       "0  truthful  conrad  positive  TripAdvisor   \n",
       "1  truthful   hyatt  positive  TripAdvisor   \n",
       "2  truthful   hyatt  positive  TripAdvisor   \n",
       "3  truthful    omni  positive  TripAdvisor   \n",
       "4  truthful   hyatt  positive  TripAdvisor   \n",
       "\n",
       "                                                text  \n",
       "0  We stayed for a one night getaway with family ...  \n",
       "1  Triple A rate with upgrade to view room was le...  \n",
       "2  This comes a little late as I'm finally catchi...  \n",
       "3  The Omni Chicago really delivers on all fronts...  \n",
       "4  I asked for a high floor away from the elevato...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/deceptive-opinion.csv\")\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Prepare the Dataset\n",
    "\n",
    "The original dataset contains multiple columns such as hotel name, polarity, and review \n",
    "source. For fake review detection, we only need:\n",
    "\n",
    "- `text`  → the review content  \n",
    "- `label` → deceptive (fake) or truthful (real)\n",
    "\n",
    "We will:\n",
    "1. Extract the relevant columns  \n",
    "2. Rename the label column  \n",
    "3. Convert labels to binary (1 = deceptive, 0 = truthful)  \n",
    "4. Verify class distribution  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:00:43.884417Z",
     "iopub.status.busy": "2025-11-30T12:00:43.884045Z",
     "iopub.status.idle": "2025-11-30T12:00:43.939384Z",
     "shell.execute_reply": "2025-11-30T12:00:43.938302Z",
     "shell.execute_reply.started": "2025-11-30T12:00:43.884391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Shape: (1600, 2)\n",
      "\n",
      "Class Distribution:\n",
      "label\n",
      "0    800\n",
      "1    800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  We stayed for a one night getaway with family ...      0\n",
       "1  Triple A rate with upgrade to view room was le...      0\n",
       "2  This comes a little late as I'm finally catchi...      0\n",
       "3  The Omni Chicago really delivers on all fronts...      0\n",
       "4  I asked for a high floor away from the elevato...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/deceptive-opinion.csv\")\n",
    "\n",
    "# Keep only necessary columns\n",
    "df = df[['text', 'deceptive']].copy()\n",
    "\n",
    "# Rename label column\n",
    "df.rename(columns={'deceptive': 'label'}, inplace=True)\n",
    "\n",
    "# Convert labels to binary\n",
    "df['label'] = df['label'].map({'deceptive': 1, 'truthful': 0})\n",
    "\n",
    "print(\"Cleaned Dataset Shape:\", df.shape)\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning & Preprocessing\n",
    "\n",
    "To prepare the reviews for machine learning, we apply standard NLP preprocessing:\n",
    "\n",
    "### Cleaning Steps:\n",
    "- Convert text to lowercase  \n",
    "- Remove punctuation  \n",
    "- Remove numbers  \n",
    "- Remove stopwords (e.g., \"the\", \"and\", \"is\")  \n",
    "- Apply lemmatization (normalize words to their root form)  \n",
    "\n",
    "This produces cleaner text, reduces noise, and improves model accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:02:11.017700Z",
     "iopub.status.busy": "2025-11-30T12:02:11.017331Z",
     "iopub.status.idle": "2025-11-30T12:02:17.054003Z",
     "shell.execute_reply": "2025-11-30T12:02:17.052997Z",
     "shell.execute_reply.started": "2025-11-30T12:02:11.017671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sourav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sourav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sourav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned text:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "      <td>stayed one night getaway family thursday tripl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "      <td>triple rate upgrade view room less also includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "      <td>come little late finally catching review past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "      <td>omni chicago really delivers front spaciousnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "      <td>asked high floor away elevator got room pleasa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  We stayed for a one night getaway with family ...   \n",
       "1  Triple A rate with upgrade to view room was le...   \n",
       "2  This comes a little late as I'm finally catchi...   \n",
       "3  The Omni Chicago really delivers on all fronts...   \n",
       "4  I asked for a high floor away from the elevato...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  stayed one night getaway family thursday tripl...  \n",
       "1  triple rate upgrade view room less also includ...  \n",
       "2  come little late finally catching review past ...  \n",
       "3  omni chicago really delivers front spaciousnes...  \n",
       "4  asked high floor away elevator got room pleasa...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (only first time)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords + lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply cleaning\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Sample cleaned text:\\n\")\n",
    "df[['text', 'clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split & TF-IDF Vectorization\n",
    "\n",
    "Now that the dataset is cleaned, we convert the text into numerical features using \n",
    "**TF-IDF (Term Frequency – Inverse Document Frequency)**.\n",
    "\n",
    "Steps performed:\n",
    "1. Split dataset into training and testing sets (80% train, 20% test).\n",
    "2. Convert `clean_text` into TF-IDF vectors.\n",
    "3. Limit vocabulary size to avoid overfitting and speed up training.\n",
    "4. Save the vectorizer to reuse during prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:03:10.834684Z",
     "iopub.status.busy": "2025-11-30T12:03:10.834187Z",
     "iopub.status.idle": "2025-11-30T12:03:11.291279Z",
     "shell.execute_reply": "2025-11-30T12:03:11.290101Z",
     "shell.execute_reply.started": "2025-11-30T12:03:10.834656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (1280, 5000)\n",
      "TF-IDF test shape: (320, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 702 stored elements and shape (5, 5000)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_text'], \n",
    "    df['label'], \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,   # limit vocabulary\n",
    "    ngram_range=(1,2),   # unigrams + bigrams improve accuracy\n",
    "    min_df=2             # ignore very rare words\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF test shape:\", X_test_tfidf.shape)\n",
    "\n",
    "X_train_tfidf[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "\n",
    "In this step, we train multiple machine learning models:\n",
    "\n",
    "- **Logistic Regression**\n",
    "- **Support Vector Machine (SVM)**\n",
    "- **XGBoost Classifier**\n",
    "\n",
    "For each model, we compute:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "This helps us identify the best-performing fake review detection model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:05:37.274136Z",
     "iopub.status.busy": "2025-11-30T12:05:37.273714Z",
     "iopub.status.idle": "2025-11-30T12:05:42.838916Z",
     "shell.execute_reply": "2025-11-30T12:05:42.838257Z",
     "shell.execute_reply.started": "2025-11-30T12:05:37.274110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "----------------------------------------\n",
      "Accuracy : 0.875\n",
      "Precision: 0.8658536585365854\n",
      "Recall   : 0.8875\n",
      "F1-score : 0.8765432098765432\n",
      "\n",
      "SVM Performance:\n",
      "----------------------------------------\n",
      "Accuracy : 0.878125\n",
      "Precision: 0.8711656441717791\n",
      "Recall   : 0.8875\n",
      "F1-score : 0.8792569659442725\n",
      "\n",
      "XGBoost Performance:\n",
      "----------------------------------------\n",
      "Accuracy : 0.81875\n",
      "Precision: 0.7965116279069767\n",
      "Recall   : 0.85625\n",
      "F1-score : 0.8253012048192772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------\n",
    "# Logistic Regression\n",
    "# ------------------\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "pred_lr = lr.predict(X_test_tfidf)\n",
    "\n",
    "# ------------------\n",
    "# SVM (Linear kernel)\n",
    "# ------------------\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "# ---------------\n",
    "# XGBoost\n",
    "# ---------------\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_tfidf, y_train)\n",
    "pred_xgb = xgb.predict(X_test_tfidf)\n",
    "\n",
    "# ----------------------\n",
    "# Function to evaluate\n",
    "# ----------------------\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-score :\", f1_score(y_true, y_pred))\n",
    "\n",
    "# Print results\n",
    "evaluate_model(\"Logistic Regression\", y_test, pred_lr)\n",
    "evaluate_model(\"SVM\", y_test, pred_svm)\n",
    "evaluate_model(\"XGBoost\", y_test, pred_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model and TF-IDF Vectorizer\n",
    "\n",
    "We select the best-performing model (SVM) and save:\n",
    "\n",
    "- The trained SVM model  \n",
    "- The fitted TF-IDF vectorizer  \n",
    "\n",
    "Both are saved using pickle so they can be loaded inside a Flask API for real-time\n",
    "fake review detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:06:51.403874Z",
     "iopub.status.busy": "2025-11-30T12:06:51.403386Z",
     "iopub.status.idle": "2025-11-30T12:06:51.452155Z",
     "shell.execute_reply": "2025-11-30T12:06:51.450852Z",
     "shell.execute_reply.started": "2025-11-30T12:06:51.403843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save SVM model\n",
    "with open(\"../models/final_svm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm, f)\n",
    "\n",
    "# Save TF-IDF vectorizer\n",
    "with open(\"../models/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1618,
     "sourceId": 2879,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
