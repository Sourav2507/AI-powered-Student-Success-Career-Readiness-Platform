{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:35.008329Z",
     "iopub.status.busy": "2025-11-30T06:24:35.007989Z",
     "iopub.status.idle": "2025-11-30T06:24:35.342396Z",
     "shell.execute_reply": "2025-11-30T06:24:35.341595Z",
     "shell.execute_reply.started": "2025-11-30T06:24:35.008305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:35.344566Z",
     "iopub.status.busy": "2025-11-30T06:24:35.344157Z",
     "iopub.status.idle": "2025-11-30T06:24:35.348712Z",
     "shell.execute_reply": "2025-11-30T06:24:35.347575Z",
     "shell.execute_reply.started": "2025-11-30T06:24:35.344544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OULAD Datasets\n",
    "\n",
    "In this step, we load all CSV files of the OULAD dataset into a dictionary called `dfs`.\n",
    "Each key in the dictionary corresponds to a dataset name (e.g., 'studentInfo', 'courses', etc.), \n",
    "and the value is the pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:35.349784Z",
     "iopub.status.busy": "2025-11-30T06:24:35.349496Z",
     "iopub.status.idle": "2025-11-30T06:24:45.152645Z",
     "shell.execute_reply": "2025-11-30T06:24:45.151709Z",
     "shell.execute_reply.started": "2025-11-30T06:24:35.349757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shapes\n",
      "student_info: (32593, 12)\n",
      "student_reg: (32593, 5)\n",
      "student_assess: (173912, 5)\n",
      "student_vle: (10655280, 6)\n",
      "assessments: (206, 6)\n",
      "vle: (6364, 6)\n",
      "courses: (22, 3)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "student_info= pd.read_csv(DATA_PATH + \"studentInfo.csv\")\n",
    "student_reg= pd.read_csv(DATA_PATH + \"studentRegistration.csv\")\n",
    "student_assess= pd.read_csv(DATA_PATH + \"studentAssessment.csv\")\n",
    "student_vle= pd.read_csv(DATA_PATH + \"studentVle.csv\")\n",
    "assessments= pd.read_csv(DATA_PATH + \"assessments.csv\")\n",
    "vle= pd.read_csv(DATA_PATH + \"vle.csv\")\n",
    "courses= pd.read_csv(DATA_PATH + \"courses.csv\")\n",
    "\n",
    "print(\"\\nDataset Shapes\")\n",
    "dfs = {\n",
    "    \"student_info\": student_info,\n",
    "    \"student_reg\": student_reg,\n",
    "    \"student_assess\": student_assess,\n",
    "    \"student_vle\": student_vle,\n",
    "    \"assessments\": assessments,\n",
    "    \"vle\": vle,\n",
    "    \"courses\": courses\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Values in All Tables\n",
    "Before performing any cleaning or feature engineering, we need to understand data quality.\n",
    "This step prints the total number of missing values in every dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:45.153867Z",
     "iopub.status.busy": "2025-11-30T06:24:45.153578Z",
     "iopub.status.idle": "2025-11-30T06:24:46.260899Z",
     "shell.execute_reply": "2025-11-30T06:24:46.259941Z",
     "shell.execute_reply.started": "2025-11-30T06:24:45.153841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in student_info:\n",
      "code_module                0\n",
      "code_presentation          0\n",
      "id_student                 0\n",
      "gender                     0\n",
      "region                     0\n",
      "highest_education          0\n",
      "imd_band                1111\n",
      "age_band                   0\n",
      "num_of_prev_attempts       0\n",
      "studied_credits            0\n",
      "disability                 0\n",
      "final_result               0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_reg:\n",
      "code_module                0\n",
      "code_presentation          0\n",
      "id_student                 0\n",
      "date_registration         45\n",
      "date_unregistration    22521\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_assess:\n",
      "id_assessment       0\n",
      "id_student          0\n",
      "date_submitted      0\n",
      "is_banked           0\n",
      "score             173\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_vle:\n",
      "code_module          0\n",
      "code_presentation    0\n",
      "id_student           0\n",
      "id_site              0\n",
      "date                 0\n",
      "sum_click            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in assessments:\n",
      "code_module           0\n",
      "code_presentation     0\n",
      "id_assessment         0\n",
      "assessment_type       0\n",
      "date                 11\n",
      "weight                0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in vle:\n",
      "id_site                 0\n",
      "code_module             0\n",
      "code_presentation       0\n",
      "activity_type           0\n",
      "week_from            5243\n",
      "week_to              5243\n",
      "dtype: int64\n",
      "\n",
      "Missing values in courses:\n",
      "code_module                   0\n",
      "code_presentation             0\n",
      "module_presentation_length    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for name, df in dfs.items():\n",
    "    print(f\"\\nMissing values in {name}:\")\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values\n",
    "\n",
    "We now address missing values across all datasets.\n",
    "Each dataset requires a different strategy because the columns have different meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:46.263485Z",
     "iopub.status.busy": "2025-11-30T06:24:46.263188Z",
     "iopub.status.idle": "2025-11-30T06:24:46.285916Z",
     "shell.execute_reply": "2025-11-30T06:24:46.284758Z",
     "shell.execute_reply.started": "2025-11-30T06:24:46.263464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "student_info['imd_band'] = student_info['imd_band'].fillna(student_info['imd_band'].mode()[0])\n",
    "student_reg['date_registration'] = student_reg['date_registration'].fillna(student_reg['date_registration'].median())\n",
    "student_reg['date_unregistration'] = student_reg['date_unregistration'].fillna(-1)\n",
    "student_assess['score'] = student_assess['score'].fillna(0)\n",
    "assessments['date'] = assessments['date'].fillna(assessments['date'].median())\n",
    "vle['week_from'] = vle['week_from'].fillna(-1)\n",
    "vle['week_to'] = vle['week_to'].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Missing Values After Cleaning\n",
    "\n",
    "After handling missing values, we re-check each dataset to ensure that all NA values were processed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:46.287153Z",
     "iopub.status.busy": "2025-11-30T06:24:46.286800Z",
     "iopub.status.idle": "2025-11-30T06:24:47.383699Z",
     "shell.execute_reply": "2025-11-30T06:24:47.382855Z",
     "shell.execute_reply.started": "2025-11-30T06:24:46.287121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in student_info after cleaning:\n",
      "code_module             0\n",
      "code_presentation       0\n",
      "id_student              0\n",
      "gender                  0\n",
      "region                  0\n",
      "highest_education       0\n",
      "imd_band                0\n",
      "age_band                0\n",
      "num_of_prev_attempts    0\n",
      "studied_credits         0\n",
      "disability              0\n",
      "final_result            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_reg after cleaning:\n",
      "code_module            0\n",
      "code_presentation      0\n",
      "id_student             0\n",
      "date_registration      0\n",
      "date_unregistration    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_assess after cleaning:\n",
      "id_assessment     0\n",
      "id_student        0\n",
      "date_submitted    0\n",
      "is_banked         0\n",
      "score             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in student_vle after cleaning:\n",
      "code_module          0\n",
      "code_presentation    0\n",
      "id_student           0\n",
      "id_site              0\n",
      "date                 0\n",
      "sum_click            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in assessments after cleaning:\n",
      "code_module          0\n",
      "code_presentation    0\n",
      "id_assessment        0\n",
      "assessment_type      0\n",
      "date                 0\n",
      "weight               0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in vle after cleaning:\n",
      "id_site              0\n",
      "code_module          0\n",
      "code_presentation    0\n",
      "activity_type        0\n",
      "week_from            0\n",
      "week_to              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in courses after cleaning:\n",
      "code_module                   0\n",
      "code_presentation             0\n",
      "module_presentation_length    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for name, df in dfs.items():\n",
    "    print(f\"\\nMissing values in {name} after cleaning:\")\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Core Tables\n",
    "\n",
    "Now that all datasets are clean and have no missing values, we begin merging the core tables.\n",
    "We start by merging `student_info` with `student_reg` using the shared keys:\n",
    "- code_module  \n",
    "- code_presentation  \n",
    "- id_student  \n",
    "\n",
    "This will create a unified student-level table that includes demographics and registration details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:47.385047Z",
     "iopub.status.busy": "2025-11-30T06:24:47.384734Z",
     "iopub.status.idle": "2025-11-30T06:24:47.445479Z",
     "shell.execute_reply": "2025-11-30T06:24:47.444524Z",
     "shell.execute_reply.started": "2025-11-30T06:24:47.385020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>final_result</th>\n",
       "      <th>date_registration</th>\n",
       "      <th>date_unregistration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>M</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>F</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>30268</td>\n",
       "      <td>F</td>\n",
       "      <td>North Western Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>30-40%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Y</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>F</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation  id_student gender                region  \\\n",
       "0         AAA             2013J       11391      M   East Anglian Region   \n",
       "1         AAA             2013J       28400      F              Scotland   \n",
       "2         AAA             2013J       30268      F  North Western Region   \n",
       "3         AAA             2013J       31604      F     South East Region   \n",
       "4         AAA             2013J       32885      F  West Midlands Region   \n",
       "\n",
       "       highest_education imd_band age_band  num_of_prev_attempts  \\\n",
       "0       HE Qualification  90-100%     55<=                     0   \n",
       "1       HE Qualification   20-30%    35-55                     0   \n",
       "2  A Level or Equivalent   30-40%    35-55                     0   \n",
       "3  A Level or Equivalent   50-60%    35-55                     0   \n",
       "4     Lower Than A Level   50-60%     0-35                     0   \n",
       "\n",
       "   studied_credits disability final_result  date_registration  \\\n",
       "0              240          N         Pass             -159.0   \n",
       "1               60          N         Pass              -53.0   \n",
       "2               60          Y    Withdrawn              -92.0   \n",
       "3               60          N         Pass              -52.0   \n",
       "4               60          N         Pass             -176.0   \n",
       "\n",
       "   date_unregistration  \n",
       "0                 -1.0  \n",
       "1                 -1.0  \n",
       "2                 12.0  \n",
       "3                 -1.0  \n",
       "4                 -1.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(\n",
    "    student_info,\n",
    "    student_reg,\n",
    "    on=[\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Merged Dataset\n",
    "\n",
    "Now that we have combined the key student information with registration dates,  \n",
    "we perform a basic exploration to understand the dataset structure, data types,  \n",
    "and detect any potential issues before feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:47.446706Z",
     "iopub.status.busy": "2025-11-30T06:24:47.446360Z",
     "iopub.status.idle": "2025-11-30T06:24:47.537476Z",
     "shell.execute_reply": "2025-11-30T06:24:47.536598Z",
     "shell.execute_reply.started": "2025-11-30T06:24:47.446620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32593 entries, 0 to 32592\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   code_module           32593 non-null  object \n",
      " 1   code_presentation     32593 non-null  object \n",
      " 2   id_student            32593 non-null  int64  \n",
      " 3   gender                32593 non-null  object \n",
      " 4   region                32593 non-null  object \n",
      " 5   highest_education     32593 non-null  object \n",
      " 6   imd_band              32593 non-null  object \n",
      " 7   age_band              32593 non-null  object \n",
      " 8   num_of_prev_attempts  32593 non-null  int64  \n",
      " 9   studied_credits       32593 non-null  int64  \n",
      " 10  disability            32593 non-null  object \n",
      " 11  final_result          32593 non-null  object \n",
      " 12  date_registration     32593 non-null  float64\n",
      " 13  date_unregistration   32593 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(9)\n",
      "memory usage: 3.5+ MB\n",
      "\n",
      "Summary Statistics:\n",
      "       code_module code_presentation    id_student gender    region  \\\n",
      "count        32593             32593  3.259300e+04  32593     32593   \n",
      "unique           7                 4           NaN      2        13   \n",
      "top            BBB             2014J           NaN      M  Scotland   \n",
      "freq          7909             11260           NaN  17875      3446   \n",
      "mean           NaN               NaN  7.066877e+05    NaN       NaN   \n",
      "std            NaN               NaN  5.491673e+05    NaN       NaN   \n",
      "min            NaN               NaN  3.733000e+03    NaN       NaN   \n",
      "25%            NaN               NaN  5.085730e+05    NaN       NaN   \n",
      "50%            NaN               NaN  5.903100e+05    NaN       NaN   \n",
      "75%            NaN               NaN  6.444530e+05    NaN       NaN   \n",
      "max            NaN               NaN  2.716795e+06    NaN       NaN   \n",
      "\n",
      "            highest_education imd_band age_band  num_of_prev_attempts  \\\n",
      "count                   32593    32593    32593          32593.000000   \n",
      "unique                      5       10        3                   NaN   \n",
      "top     A Level or Equivalent   20-30%     0-35                   NaN   \n",
      "freq                    14045     4765    22944                   NaN   \n",
      "mean                      NaN      NaN      NaN              0.163225   \n",
      "std                       NaN      NaN      NaN              0.479758   \n",
      "min                       NaN      NaN      NaN              0.000000   \n",
      "25%                       NaN      NaN      NaN              0.000000   \n",
      "50%                       NaN      NaN      NaN              0.000000   \n",
      "75%                       NaN      NaN      NaN              0.000000   \n",
      "max                       NaN      NaN      NaN              6.000000   \n",
      "\n",
      "        studied_credits disability final_result  date_registration  \\\n",
      "count      32593.000000      32593        32593       32593.000000   \n",
      "unique              NaN          2            4                NaN   \n",
      "top                 NaN          N         Pass                NaN   \n",
      "freq                NaN      29429        12361                NaN   \n",
      "mean          79.758691        NaN          NaN         -69.394164   \n",
      "std           41.071900        NaN          NaN          49.228660   \n",
      "min           30.000000        NaN          NaN        -322.000000   \n",
      "25%           60.000000        NaN          NaN        -100.000000   \n",
      "50%           60.000000        NaN          NaN         -57.000000   \n",
      "75%          120.000000        NaN          NaN         -29.000000   \n",
      "max          655.000000        NaN          NaN         167.000000   \n",
      "\n",
      "        date_unregistration  \n",
      "count          32593.000000  \n",
      "unique                  NaN  \n",
      "top                     NaN  \n",
      "freq                    NaN  \n",
      "mean              14.685301  \n",
      "std               51.490677  \n",
      "min             -365.000000  \n",
      "25%               -1.000000  \n",
      "50%               -1.000000  \n",
      "75%               -1.000000  \n",
      "max              444.000000  \n"
     ]
    }
   ],
   "source": [
    "merged_df.info()\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(merged_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Assessment and VLE Tables\n",
    "\n",
    "Before merging everything into one modeling dataset, we must aggregate the\n",
    "large tables (`student_assess` and `student_vle`) into student-level features.\n",
    "\n",
    "This reduces tens of millions of records into manageable feature tables.\n",
    "\n",
    "We will create:\n",
    "- Total assessment score per student\n",
    "- Average assessment score\n",
    "- Number of assessments attempted\n",
    "- Total VLE clicks per student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:47.538632Z",
     "iopub.status.busy": "2025-11-30T06:24:47.538391Z",
     "iopub.status.idle": "2025-11-30T06:24:47.778352Z",
     "shell.execute_reply": "2025-11-30T06:24:47.777490Z",
     "shell.execute_reply.started": "2025-11-30T06:24:47.538611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_student  total_score  avg_score  num_assessments\n",
      "0        6516        309.0  61.800000                5\n",
      "1        8462        609.0  87.000000                7\n",
      "2       11391        410.0  82.000000                5\n",
      "3       23629        330.0  82.500000                4\n",
      "4       23698        670.0  74.444444                9\n",
      "   id_student  total_clicks\n",
      "0        6516          2791\n",
      "1        8462           656\n",
      "2       11391           934\n",
      "3       23629           161\n",
      "4       23698           910\n"
     ]
    }
   ],
   "source": [
    "assess_agg = student_assess.groupby('id_student').agg(\n",
    "    total_score=('score', 'sum'),\n",
    "    avg_score=('score', 'mean'),\n",
    "    num_assessments=('score', 'count')\n",
    ").reset_index()\n",
    "\n",
    "vle_agg = student_vle.groupby('id_student').agg(\n",
    "    total_clicks=('sum_click', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(assess_agg.head())\n",
    "print(vle_agg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have created aggregated features from the Assessment and VLE datasets,\n",
    "we merge them into the main student_info table.\n",
    "This gives us one consolidated dataset containing demographics, registration details,\n",
    "assessment performance, and online activity metrics for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:47.779536Z",
     "iopub.status.busy": "2025-11-30T06:24:47.779228Z",
     "iopub.status.idle": "2025-11-30T06:24:47.803043Z",
     "shell.execute_reply": "2025-11-30T06:24:47.801956Z",
     "shell.execute_reply.started": "2025-11-30T06:24:47.779511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "assess_features = (\n",
    "    student_assess\n",
    "    .groupby(\"id_student\")\n",
    "    .agg(\n",
    "        total_score=(\"score\", \"sum\"),\n",
    "        avg_score=(\"score\", \"mean\"),\n",
    "        num_assessments=(\"id_assessment\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:47.804379Z",
     "iopub.status.busy": "2025-11-30T06:24:47.804150Z",
     "iopub.status.idle": "2025-11-30T06:24:48.013883Z",
     "shell.execute_reply": "2025-11-30T06:24:48.012566Z",
     "shell.execute_reply.started": "2025-11-30T06:24:47.804360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vle_features = (\n",
    "    student_vle\n",
    "    .groupby(\"id_student\")\n",
    "    .agg(\n",
    "        total_clicks=(\"sum_click\", \"sum\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:48.015130Z",
     "iopub.status.busy": "2025-11-30T06:24:48.014848Z",
     "iopub.status.idle": "2025-11-30T06:24:48.044286Z",
     "shell.execute_reply": "2025-11-30T06:24:48.043499Z",
     "shell.execute_reply.started": "2025-11-30T06:24:48.015100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "student_info = student_info.merge(assess_features, on=\"id_student\", how=\"left\")\n",
    "\n",
    "student_info = student_info.merge(vle_features, on=\"id_student\", how=\"left\")\n",
    "\n",
    "student_info['total_score'] = student_info['total_score'].fillna(0)\n",
    "student_info['avg_score'] = student_info['avg_score'].fillna(0)\n",
    "student_info['num_assessments'] = student_info['num_assessments'].fillna(0)\n",
    "student_info['total_clicks'] = student_info['total_clicks'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML Targets (Classification + Regression)\n",
    "\n",
    "We convert the `final_result` column into:\n",
    "- `target_pass` → binary classification (1 = Pass/Distinction, 0 = Fail/Withdrawn)\n",
    "- `target_cgpa` → ordinal regression scale (0–3), similar to CGPA grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:48.045444Z",
     "iopub.status.busy": "2025-11-30T06:24:48.045191Z",
     "iopub.status.idle": "2025-11-30T06:24:48.064896Z",
     "shell.execute_reply": "2025-11-30T06:24:48.063898Z",
     "shell.execute_reply.started": "2025-11-30T06:24:48.045423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_result</th>\n",
       "      <th>target_pass</th>\n",
       "      <th>target_cgpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fail</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pass</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   final_result  target_pass  target_cgpa\n",
       "0          Pass            1            2\n",
       "1          Pass            1            2\n",
       "2     Withdrawn            0            0\n",
       "3          Pass            1            2\n",
       "4          Pass            1            2\n",
       "5          Pass            1            2\n",
       "6          Pass            1            2\n",
       "7          Pass            1            2\n",
       "8          Pass            1            2\n",
       "9          Pass            1            2\n",
       "10         Pass            1            2\n",
       "11         Pass            1            2\n",
       "12         Pass            1            2\n",
       "13         Pass            1            2\n",
       "14         Pass            1            2\n",
       "15    Withdrawn            0            0\n",
       "16         Pass            1            2\n",
       "17         Pass            1            2\n",
       "18         Fail            0            1\n",
       "19         Pass            1            2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_info['target_pass'] = student_info['final_result'].map({\n",
    "    'Pass': 1,\n",
    "    'Distinction': 1,\n",
    "    'Fail': 0,\n",
    "    'Withdrawn': 0\n",
    "})\n",
    "\n",
    "student_info['target_cgpa'] = student_info['final_result'].map({\n",
    "    'Distinction': 3,\n",
    "    'Pass': 2,\n",
    "    'Fail': 1,\n",
    "    'Withdrawn': 0\n",
    "})\n",
    "\n",
    "student_info[['final_result', 'target_pass', 'target_cgpa']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge student_info with student_reg\n",
    "\n",
    "student_info does not contain registration dates.  \n",
    "To create registration-based features, we must merge student_info and student_registration on:\n",
    "- code_module\n",
    "- code_presentation\n",
    "- id_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:48.069996Z",
     "iopub.status.busy": "2025-11-30T06:24:48.069702Z",
     "iopub.status.idle": "2025-11-30T06:24:48.099833Z",
     "shell.execute_reply": "2025-11-30T06:24:48.099050Z",
     "shell.execute_reply.started": "2025-11-30T06:24:48.069971Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before merge: (32593, 18)\n",
      "Shape after merge : (32593, 20)\n",
      "\n",
      "Columns now available:\n",
      "Index(['code_module', 'code_presentation', 'id_student', 'gender', 'region',\n",
      "       'highest_education', 'imd_band', 'age_band', 'num_of_prev_attempts',\n",
      "       'studied_credits', 'disability', 'final_result', 'total_score',\n",
      "       'avg_score', 'num_assessments', 'total_clicks', 'target_pass',\n",
      "       'target_cgpa', 'date_registration', 'date_unregistration'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# === Cell 9B — Merge student_info with student_reg === #\n",
    "\n",
    "# merge on common keys\n",
    "student_info_merged = student_info.merge(\n",
    "    student_reg,\n",
    "    on=[\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Shape before merge:\", student_info.shape)\n",
    "print(\"Shape after merge :\", student_info_merged.shape)\n",
    "print(\"\\nColumns now available:\")\n",
    "print(student_info_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Create numeric features useful for modeling:\n",
    "- `registered_flag` — whether student ever unregistered (0/1)\n",
    "- `registration_lead_days` — days before module start the student registered (positive number)\n",
    "- `registration_duration` — days between registration and unregistration (if unregistered; -1 otherwise)\n",
    "- Numeric encodings:\n",
    "  - `imd_num` — midpoint of IMD band (0–100)\n",
    "  - `age_num` — approximate numeric age from `age_band`\n",
    "  - `edu_level` — ordinal encoding of `highest_education`\n",
    "  - `gender_m` — binary gender (M=1, F=0)\n",
    "  - `disability_flag` — binary disability (Y=1, N=0)\n",
    "- Interaction features:\n",
    "  - `clicks_per_credit` = total_clicks / studied_credits\n",
    "  - `score_per_assess` = total_score / num_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:48.100989Z",
     "iopub.status.busy": "2025-11-30T06:24:48.100697Z",
     "iopub.status.idle": "2025-11-30T06:24:49.159127Z",
     "shell.execute_reply": "2025-11-30T06:24:49.158042Z",
     "shell.execute_reply.started": "2025-11-30T06:24:48.100962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling dataframe shape: (32593, 22)\n",
      "\n",
      "Dtypes:\n",
      "code_module                object\n",
      "code_presentation          object\n",
      "id_student                  int64\n",
      "gender_m                    int64\n",
      "region                     object\n",
      "edu_level                   int64\n",
      "imd_num                   float64\n",
      "age_num                   float64\n",
      "num_of_prev_attempts        int64\n",
      "studied_credits             int64\n",
      "disability_flag             int64\n",
      "total_score               float64\n",
      "avg_score                 float64\n",
      "num_assessments           float64\n",
      "total_clicks              float64\n",
      "registration_lead_days    float64\n",
      "registered_flag             int64\n",
      "registration_duration     float64\n",
      "clicks_per_credit         float64\n",
      "score_per_assess          float64\n",
      "target_pass                 int64\n",
      "target_cgpa                 int64\n",
      "dtype: object\n",
      "\n",
      "First 8 rows:\n",
      "  code_module code_presentation  id_student  gender_m                region  \\\n",
      "0         AAA             2013J       11391         1   East Anglian Region   \n",
      "1         AAA             2013J       28400         0              Scotland   \n",
      "2         AAA             2013J       30268         0  North Western Region   \n",
      "3         AAA             2013J       31604         0     South East Region   \n",
      "4         AAA             2013J       32885         0  West Midlands Region   \n",
      "5         AAA             2013J       38053         1                 Wales   \n",
      "6         AAA             2013J       45462         1              Scotland   \n",
      "7         AAA             2013J       45642         0  North Western Region   \n",
      "\n",
      "   edu_level  imd_num  age_num  num_of_prev_attempts  studied_credits  ...  \\\n",
      "0          3     95.0     60.0                     0              240  ...   \n",
      "1          3     25.0     45.0                     0               60  ...   \n",
      "2          2     35.0     45.0                     0               60  ...   \n",
      "3          2     55.0     45.0                     0               60  ...   \n",
      "4          1     55.0     17.5                     0               60  ...   \n",
      "5          2     85.0     45.0                     0               60  ...   \n",
      "6          3     35.0     17.5                     0               60  ...   \n",
      "7          2     95.0     17.5                     0              120  ...   \n",
      "\n",
      "   avg_score  num_assessments  total_clicks  registration_lead_days  \\\n",
      "0       82.0              5.0         934.0                   159.0   \n",
      "1       66.4              5.0        1435.0                    53.0   \n",
      "2        0.0              0.0         281.0                    92.0   \n",
      "3       76.0              5.0        2158.0                    52.0   \n",
      "4       54.4              5.0        1034.0                   176.0   \n",
      "5       68.0              5.0        2445.0                   110.0   \n",
      "6       68.0              5.0        1492.0                    67.0   \n",
      "7       72.4              5.0        1428.0                    29.0   \n",
      "\n",
      "   registered_flag  registration_duration  clicks_per_credit  \\\n",
      "0                0                   -1.0           3.891667   \n",
      "1                0                   -1.0          23.916667   \n",
      "2                1                  104.0           4.683333   \n",
      "3                0                   -1.0          35.966667   \n",
      "4                0                   -1.0          17.233333   \n",
      "5                0                   -1.0          40.750000   \n",
      "6                0                   -1.0          24.866667   \n",
      "7                0                   -1.0          11.900000   \n",
      "\n",
      "   score_per_assess  target_pass  target_cgpa  \n",
      "0              82.0            1            2  \n",
      "1              66.4            1            2  \n",
      "2               0.0            0            0  \n",
      "3              76.0            1            2  \n",
      "4              54.4            1            2  \n",
      "5              68.0            1            2  \n",
      "6              68.0            1            2  \n",
      "7              72.4            1            2  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "\n",
      "Summary statistics (numeric):\n",
      "                          count           mean            std     min  \\\n",
      "id_student              32593.0  706687.669131  549167.313855  3733.0   \n",
      "gender_m                32593.0       0.548431       0.497657     0.0   \n",
      "edu_level               32593.0       1.720124       0.716310     0.0   \n",
      "imd_num                 32593.0      46.361642      27.963838     5.0   \n",
      "age_num                 32593.0      25.740650      12.764772    17.5   \n",
      "num_of_prev_attempts    32593.0       0.163225       0.479758     0.0   \n",
      "studied_credits         32593.0      79.758691      41.071900    30.0   \n",
      "disability_flag         32593.0       0.097076       0.296066     0.0   \n",
      "total_score             32593.0     479.098150     408.394415     0.0   \n",
      "avg_score               32593.0      59.648430      31.335383     0.0   \n",
      "num_assessments         32593.0       6.360844       5.076468     0.0   \n",
      "total_clicks            32593.0    1479.033412    2011.390856     0.0   \n",
      "registration_lead_days  32593.0      69.394164      49.228660  -167.0   \n",
      "registered_flag         32593.0       0.304513       0.460208     0.0   \n",
      "registration_duration   32593.0      38.604762      76.511982  -308.0   \n",
      "clicks_per_credit       32593.0      22.591650      33.719952     0.0   \n",
      "score_per_assess        32593.0      59.648430      31.335383     0.0   \n",
      "target_pass             32593.0       0.472034       0.499225     0.0   \n",
      "target_cgpa             32593.0       1.253214       0.998944     0.0   \n",
      "\n",
      "                                  25%        50%            75%           max  \n",
      "id_student              508573.000000  590310.00  644453.000000  2.716795e+06  \n",
      "gender_m                     0.000000       1.00       1.000000  1.000000e+00  \n",
      "edu_level                    1.000000       2.00       2.000000  3.000000e+00  \n",
      "imd_num                     25.000000      45.00      75.000000  9.500000e+01  \n",
      "age_num                     17.500000      17.50      45.000000  6.000000e+01  \n",
      "num_of_prev_attempts         0.000000       0.00       0.000000  6.000000e+00  \n",
      "studied_credits             60.000000      60.00     120.000000  6.550000e+02  \n",
      "disability_flag              0.000000       0.00       0.000000  1.000000e+00  \n",
      "total_score                 92.000000     392.00     809.000000  2.718000e+03  \n",
      "avg_score                   50.000000      71.20      82.200000  1.000000e+02  \n",
      "num_assessments              2.000000       6.00      11.000000  2.800000e+01  \n",
      "total_clicks               205.000000     758.00    1990.000000  2.861500e+04  \n",
      "registration_lead_days      29.000000      57.00     100.000000  3.220000e+02  \n",
      "registered_flag              0.000000       0.00       1.000000  1.000000e+00  \n",
      "registration_duration       -1.000000      -1.00      43.000000  5.310000e+02  \n",
      "clicks_per_credit            2.666667      11.15      29.033333  8.122667e+02  \n",
      "score_per_assess            50.000000      71.20      82.200000  1.000000e+02  \n",
      "target_pass                  0.000000       0.00       1.000000  1.000000e+00  \n",
      "target_cgpa                  0.000000       1.00       2.000000  3.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# === Cell 10: Feature engineering (CORRECTED) === #\n",
    "\n",
    "df = student_info_merged.copy()  # FIXED: use merged dataframe with registration dates\n",
    "\n",
    "# 1) Flags and registration-derived features\n",
    "df['registration_lead_days'] = df['date_registration'].apply(lambda x: -x)\n",
    "\n",
    "df['registered_flag'] = (df['date_unregistration'] != -1).astype(int)\n",
    "\n",
    "df['registration_duration'] = df.apply(\n",
    "    lambda r: (r['date_unregistration'] - r['date_registration']) if r['date_unregistration'] != -1 else -1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 2) Numeric IMD conversion\n",
    "def imd_to_mid(s):\n",
    "    try:\n",
    "        if pd.isna(s) or s == 'Unknown':\n",
    "            return np.nan\n",
    "        s2 = s.replace('%','')\n",
    "        if '<=' in s2:\n",
    "            parts = s2.replace('<=','').split('-')\n",
    "        else:\n",
    "            parts = s2.split('-')\n",
    "        parts = [p for p in parts if p!='']\n",
    "        if len(parts) == 1:\n",
    "            return float(parts[0])\n",
    "        low = float(parts[0])\n",
    "        high = float(parts[-1])\n",
    "        return (low + high) / 2.0\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['imd_num'] = df['imd_band'].astype(str).apply(imd_to_mid)\n",
    "\n",
    "df['imd_num'] = df['imd_num'].fillna(df['imd_num'].median())\n",
    "\n",
    "# 3) Age numeric\n",
    "age_map = {\n",
    "    '0-35': 17.5,\n",
    "    '35-55': 45.0,\n",
    "    '55<=': 60.0\n",
    "}\n",
    "\n",
    "df['age_band'] = df['age_band'].astype(str).str.strip()\n",
    "\n",
    "# extract fallback number (first number in string)\n",
    "placeholder_age = (\n",
    "    df['age_band']\n",
    "    .str.extract('(\\d+)')[0]\n",
    "    .astype(float)\n",
    "    .fillna(30.0)\n",
    ")\n",
    "\n",
    "df['age_num'] = df['age_band'].map(age_map)\n",
    "df['age_num'] = df['age_num'].fillna(placeholder_age)\n",
    "\n",
    "\n",
    "# 4) Highest Education Encoding\n",
    "edu_map = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Postgraduate Qualification': 4\n",
    "}\n",
    "df['edu_level'] = df['highest_education'].map(edu_map).fillna(\n",
    "    df['highest_education'].mode().iloc[0]\n",
    ")\n",
    "df['edu_level'] = pd.to_numeric(df['edu_level'], errors='coerce').fillna(2).astype(int)\n",
    "\n",
    "# 5) Gender & Disability\n",
    "df['gender_m'] = df['gender'].map({'M': 1, 'F': 0}).fillna(0).astype(int)\n",
    "df['disability_flag'] = df['disability'].map({'Y': 1, 'N': 0}).fillna(0).astype(int)\n",
    "\n",
    "# 6) Interaction Features\n",
    "df['clicks_per_credit'] = df.apply(\n",
    "    lambda r: r['total_clicks'] / r['studied_credits'] if r['studied_credits'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['score_per_assess'] = df.apply(\n",
    "    lambda r: r['total_score'] / r['num_assessments'] if r['num_assessments'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 7) Select modeling features\n",
    "model_cols = [\n",
    "    'code_module','code_presentation','id_student','gender_m','region','edu_level','imd_num','age_num',\n",
    "    'num_of_prev_attempts','studied_credits','disability_flag',\n",
    "    'total_score','avg_score','num_assessments','total_clicks',\n",
    "    'registration_lead_days','registered_flag','registration_duration',\n",
    "    'clicks_per_credit','score_per_assess',\n",
    "    'target_pass','target_cgpa'\n",
    "]\n",
    "\n",
    "modeling_df = df[model_cols].copy()\n",
    "\n",
    "# 8) Clean NaN/inf\n",
    "num_cols = modeling_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "modeling_df[num_cols] = modeling_df[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# 9) Quick checks\n",
    "print(\"Modeling dataframe shape:\", modeling_df.shape)\n",
    "print(\"\\nDtypes:\")\n",
    "print(modeling_df.dtypes)\n",
    "print(\"\\nFirst 8 rows:\")\n",
    "print(modeling_df.head(8))\n",
    "print(\"\\nSummary statistics (numeric):\")\n",
    "print(modeling_df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train–Test Split for Classification & Regression\n",
    "\n",
    "We now prepare the dataset for modeling.  \n",
    "Since we have **two prediction tasks**:\n",
    "\n",
    "1. **Classification:** `target_pass` (0/1)\n",
    "2. **Regression:** `target_cgpa` (0–3 scaled CGPA)\n",
    "\n",
    "We will:\n",
    "\n",
    "- Separate input features (X) and targets (y)\n",
    "- Perform a **train–test split** (80% train, 20% test)\n",
    "- Do this separately for:\n",
    "  - Pass/Fail Classification Model\n",
    "  - CGPA Regression Model\n",
    "\n",
    "No scaling is applied yet — that will come in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:49.160312Z",
     "iopub.status.busy": "2025-11-30T06:24:49.159996Z",
     "iopub.status.idle": "2025-11-30T06:24:49.900958Z",
     "shell.execute_reply": "2025-11-30T06:24:49.900201Z",
     "shell.execute_reply.started": "2025-11-30T06:24:49.160275Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification shapes:\n",
      "X_train: (26074, 19) X_test: (6519, 19)\n",
      "y_train: (26074,) y_test: (6519,)\n",
      "\n",
      "Regression shapes:\n",
      "X_train: (26074, 19) X_test: (6519, 19)\n",
      "y_train: (26074,) y_test: (6519,)\n",
      "\n",
      "Feature columns used:\n",
      "['code_module', 'code_presentation', 'gender_m', 'region', 'edu_level', 'imd_num', 'age_num', 'num_of_prev_attempts', 'studied_credits', 'disability_flag', 'total_score', 'avg_score', 'num_assessments', 'total_clicks', 'registration_lead_days', 'registered_flag', 'registration_duration', 'clicks_per_credit', 'score_per_assess']\n"
     ]
    }
   ],
   "source": [
    "# === Cell 11: Train–Test Split === #\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Copy modeling_df created earlier\n",
    "df_model = modeling_df.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Features list (exclude targets and IDs)\n",
    "# -----------------------------\n",
    "feature_cols = [\n",
    "    col for col in df_model.columns\n",
    "    if col not in ['target_pass', 'target_cgpa', 'id_student']\n",
    "]\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "\n",
    "# Targets\n",
    "y_class = df_model['target_pass']\n",
    "y_reg = df_model['target_cgpa']\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Train–test split\n",
    "# -----------------------------\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Classification shapes:\")\n",
    "print(\"X_train:\", X_train_class.shape, \"X_test:\", X_test_class.shape)\n",
    "print(\"y_train:\", y_train_class.shape, \"y_test:\", y_test_class.shape)\n",
    "\n",
    "print(\"\\nRegression shapes:\")\n",
    "print(\"X_train:\", X_train_reg.shape, \"X_test:\", X_test_reg.shape)\n",
    "print(\"y_train:\", y_train_reg.shape, \"y_test:\", y_test_reg.shape)\n",
    "\n",
    "print(\"\\nFeature columns used:\")\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of Non-numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:49.902224Z",
     "iopub.status.busy": "2025-11-30T06:24:49.901811Z",
     "iopub.status.idle": "2025-11-30T06:24:49.909512Z",
     "shell.execute_reply": "2025-11-30T06:24:49.908728Z",
     "shell.execute_reply.started": "2025-11-30T06:24:49.902201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code_module', 'code_presentation', 'region'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find columns with non-numeric data in X\n",
    "non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
    "non_numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:49.910985Z",
     "iopub.status.busy": "2025-11-30T06:24:49.910435Z",
     "iopub.status.idle": "2025-11-30T06:24:49.932847Z",
     "shell.execute_reply": "2025-11-30T06:24:49.931893Z",
     "shell.execute_reply.started": "2025-11-30T06:24:49.910957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_module ['AAA' 'BBB' 'CCC' 'DDD' 'EEE' 'FFF' 'GGG']\n",
      "code_presentation ['2013J' '2014J' '2013B' '2014B']\n",
      "region ['East Anglian Region' 'Scotland' 'North Western Region'\n",
      " 'South East Region' 'West Midlands Region' 'Wales' 'North Region'\n",
      " 'South Region' 'Ireland' 'South West Region' 'East Midlands Region'\n",
      " 'Yorkshire Region' 'London Region']\n"
     ]
    }
   ],
   "source": [
    "for col in non_numeric_cols:\n",
    "    print(col, X[col].unique()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode remaining categorical columns\n",
    "\n",
    "Machine-learning models require all features to be numeric.  \n",
    "This step converts these categorical columns into numeric form using Label Encoding:\n",
    "\n",
    "- `code_module`\n",
    "- `code_presentation`\n",
    "- `region`\n",
    "\n",
    "After encoding, the feature matrix is rebuilt and checked for any remaining non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:49.934055Z",
     "iopub.status.busy": "2025-11-30T06:24:49.933764Z",
     "iopub.status.idle": "2025-11-30T06:24:49.969757Z",
     "shell.execute_reply": "2025-11-30T06:24:49.968973Z",
     "shell.execute_reply.started": "2025-11-30T06:24:49.934032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_module encoded. Classes: ['AAA', 'BBB', 'CCC', 'DDD', 'EEE', 'FFF', 'GGG']\n",
      "code_presentation encoded. Classes: ['2013B', '2013J', '2014B', '2014J']\n",
      "region encoded. Classes: ['East Anglian Region', 'East Midlands Region', 'Ireland', 'London Region', 'North Region', 'North Western Region', 'Scotland', 'South East Region', 'South Region', 'South West Region', 'Wales', 'West Midlands Region', 'Yorkshire Region']\n",
      "\n",
      "Remaining non-numeric columns: []\n",
      "All features are now numeric. Ready for modeling.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 12: Encode Remaining Categorical Columns === #\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_model = df_model.copy()\n",
    "\n",
    "# Categorical columns that must be numeric\n",
    "cat_cols = ['code_module', 'code_presentation', 'region']\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f\"{col} encoded. Classes: {list(le.classes_)}\")\n",
    "\n",
    "# Recreate feature matrix and targets\n",
    "feature_cols = [\n",
    "    col for col in df_model.columns\n",
    "    if col not in ['target_pass', 'target_cgpa', 'id_student']\n",
    "]\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y_class = df_model['target_pass']\n",
    "y_reg = df_model['target_cgpa']\n",
    "\n",
    "print(\"\\nRemaining non-numeric columns:\",\n",
    "      X.select_dtypes(include='object').columns.tolist())\n",
    "\n",
    "print(\"All features are now numeric. Ready for modeling.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate Train–Test Split After Encoding\n",
    "\n",
    "Since categorical features were encoded after the initial split,  \n",
    "we must rebuild the feature matrix `X` and re-run the train–test split.\n",
    "\n",
    "This ensures the model receives fully numeric data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:49.970864Z",
     "iopub.status.busy": "2025-11-30T06:24:49.970559Z",
     "iopub.status.idle": "2025-11-30T06:24:50.003750Z",
     "shell.execute_reply": "2025-11-30T06:24:50.002893Z",
     "shell.execute_reply.started": "2025-11-30T06:24:49.970838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification shapes: (26074, 19) (26074,)\n",
      "Regression shapes: (26074, 19) (26074,)\n",
      "All features numeric?: [dtype('int64') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "# Rebuild X using the now-encoded df_model\n",
    "feature_cols = [\n",
    "    col for col in df_model.columns\n",
    "    if col not in ['target_pass', 'target_cgpa', 'id_student']\n",
    "]\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "\n",
    "# Targets\n",
    "y_class = df_model['target_pass']\n",
    "y_reg = df_model['target_cgpa']\n",
    "\n",
    "# Re-do train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Classification shapes:\", X_train_class.shape, y_train_class.shape)\n",
    "print(\"Regression shapes:\", X_train_reg.shape, y_train_reg.shape)\n",
    "print(\"All features numeric?:\", X_train_class.dtypes.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Classification)\n",
    "\n",
    "We train a Logistic Regression model on the encoded and split dataset.  \n",
    "Warnings related to convergence are suppressed for cleaner output.\n",
    "\n",
    "The model performance is evaluated using:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:50.004911Z",
     "iopub.status.busy": "2025-11-30T06:24:50.004616Z",
     "iopub.status.idle": "2025-11-30T06:24:52.855091Z",
     "shell.execute_reply": "2025-11-30T06:24:52.853675Z",
     "shell.execute_reply.started": "2025-11-30T06:24:50.004891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "-------------------------------\n",
      "Accuracy : 0.8909341923607915\n",
      "Precision: 0.8646732429099877\n",
      "Recall   : 0.9116022099447514\n",
      "F1-score : 0.8875177978168012\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Train Logistic Regression for classification\n",
    "clf_lr = LogisticRegression(max_iter=500)  # increased max_iter to avoid convergence warning\n",
    "\n",
    "clf_lr.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = clf_lr.predict(X_test_class)\n",
    "\n",
    "# Evaluation\n",
    "acc_lr = accuracy_score(y_test_class, y_pred_lr)\n",
    "prec_lr = precision_score(y_test_class, y_pred_lr)\n",
    "rec_lr = recall_score(y_test_class, y_pred_lr)\n",
    "f1_lr = f1_score(y_test_class, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Accuracy :\", acc_lr)\n",
    "print(\"Precision:\", prec_lr)\n",
    "print(\"Recall   :\", rec_lr)\n",
    "print(\"F1-score :\", f1_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Random Forest is an ensemble model that builds multiple decision trees and aggregates their predictions to improve accuracy and reduce overfitting.\n",
    "\n",
    "It is capable of capturing complex, non-linear patterns in the dataset, making it a strong candidate for classification tasks.\n",
    "\n",
    "The following code trains a Random Forest classifier and evaluates it using:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "All warnings are suppressed for cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:24:52.856227Z",
     "iopub.status.busy": "2025-11-30T06:24:52.855947Z",
     "iopub.status.idle": "2025-11-30T06:25:00.593026Z",
     "shell.execute_reply": "2025-11-30T06:25:00.592248Z",
     "shell.execute_reply.started": "2025-11-30T06:24:52.856205Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "--------------------------\n",
      "Accuracy : 0.9242215063660071\n",
      "Precision: 0.8945921173235564\n",
      "Recall   : 0.9515762105947352\n",
      "F1-score : 0.9222047244094488\n"
     ]
    }
   ],
   "source": [
    "# === Random Forest Classifier === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize Random Forest\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf_rf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = clf_rf.predict(X_test_class)\n",
    "\n",
    "# Evaluation metrics\n",
    "acc_rf = accuracy_score(y_test_class, y_pred_rf)\n",
    "prec_rf = precision_score(y_test_class, y_pred_rf)\n",
    "rec_rf = recall_score(y_test_class, y_pred_rf)\n",
    "f1_rf = f1_score(y_test_class, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Accuracy :\", acc_rf)\n",
    "print(\"Precision:\", prec_rf)\n",
    "print(\"Recall   :\", rec_rf)\n",
    "print(\"F1-score :\", f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) Classifier\n",
    "\n",
    "SVM is a powerful classification algorithm that tries to find the optimal separating boundary (hyperplane) between classes.\n",
    "\n",
    "It is effective for:\n",
    "- High-dimensional data  \n",
    "- Non-linear relationships (with kernel tricks)\n",
    "\n",
    "In this step, we train an SVM classifier using the RBF kernel and evaluate it using the standard metrics:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  \n",
    "\n",
    "All warnings are suppressed for clean output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:25:00.594191Z",
     "iopub.status.busy": "2025-11-30T06:25:00.593840Z",
     "iopub.status.idle": "2025-11-30T06:26:28.391911Z",
     "shell.execute_reply": "2025-11-30T06:26:28.391118Z",
     "shell.execute_reply.started": "2025-11-30T06:25:00.594170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Performance:\n",
      "---------------------------\n",
      "Accuracy : 0.8854118729866544\n",
      "Precision: 0.8279842342342343\n",
      "Recall   : 0.9558011049723757\n",
      "F1-score : 0.887313320259466\n"
     ]
    }
   ],
   "source": [
    "# === Support Vector Machine (SVM) Classifier === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize SVM model\n",
    "clf_svm = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf_svm.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = clf_svm.predict(X_test_class)\n",
    "\n",
    "# Evaluation metrics\n",
    "acc_svm = accuracy_score(y_test_class, y_pred_svm)\n",
    "prec_svm = precision_score(y_test_class, y_pred_svm)\n",
    "rec_svm = recall_score(y_test_class, y_pred_svm)\n",
    "f1_svm = f1_score(y_test_class, y_pred_svm)\n",
    "\n",
    "print(\"SVM Classifier Performance:\")\n",
    "print(\"---------------------------\")\n",
    "print(\"Accuracy :\", acc_svm)\n",
    "print(\"Precision:\", prec_svm)\n",
    "print(\"Recall   :\", rec_svm)\n",
    "print(\"F1-score :\", f1_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "Gradient Boosting is an ensemble method that builds models sequentially, where each new model corrects the errors of the previous one.\n",
    "\n",
    "It is known for:\n",
    "- Strong predictive power  \n",
    "- Ability to handle complex patterns  \n",
    "- Usually better performance than individual models  \n",
    "\n",
    "In this step, we train a Gradient Boosting Classifier and evaluate it using:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  \n",
    "\n",
    "Warnings are suppressed for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:28.393100Z",
     "iopub.status.busy": "2025-11-30T06:26:28.392829Z",
     "iopub.status.idle": "2025-11-30T06:26:34.079275Z",
     "shell.execute_reply": "2025-11-30T06:26:34.078491Z",
     "shell.execute_reply.started": "2025-11-30T06:26:28.393057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Performance:\n",
      "------------------------------\n",
      "Accuracy : 0.9208467556373677\n",
      "Precision: 0.8830391863595572\n",
      "Recall   : 0.95937601559961\n",
      "F1-score : 0.9196261682242991\n"
     ]
    }
   ],
   "source": [
    "# === Gradient Boosting Classifier === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize model\n",
    "clf_gb = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "clf_gb.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = clf_gb.predict(X_test_class)\n",
    "\n",
    "# Evaluation\n",
    "acc_gb = accuracy_score(y_test_class, y_pred_gb)\n",
    "prec_gb = precision_score(y_test_class, y_pred_gb)\n",
    "rec_gb = recall_score(y_test_class, y_pred_gb)\n",
    "f1_gb = f1_score(y_test_class, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting Performance:\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Accuracy :\", acc_gb)\n",
    "print(\"Precision:\", prec_gb)\n",
    "print(\"Recall   :\", rec_gb)\n",
    "print(\"F1-score :\", f1_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier\n",
    "\n",
    "AdaBoost (Adaptive Boosting) is an ensemble technique that combines many weak learners, usually decision trees, to produce a strong classifier.\n",
    "\n",
    "Key characteristics:\n",
    "- Focuses more on samples misclassified by earlier learners  \n",
    "- Often performs well on clean, structured datasets  \n",
    "- Less prone to overfitting than many other ensemble methods  \n",
    "\n",
    "In this step, we train an AdaBoost Classifier and evaluate it using:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  \n",
    "\n",
    "All warnings are suppressed for cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:34.080476Z",
     "iopub.status.busy": "2025-11-30T06:26:34.080112Z",
     "iopub.status.idle": "2025-11-30T06:26:39.505831Z",
     "shell.execute_reply": "2025-11-30T06:26:39.504910Z",
     "shell.execute_reply.started": "2025-11-30T06:26:34.080454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Performance:\n",
      "----------------------\n",
      "Accuracy : 0.9018254333486732\n",
      "Precision: 0.8574361982986213\n",
      "Recall   : 0.9499512512187195\n",
      "F1-score : 0.9013259327782918\n"
     ]
    }
   ],
   "source": [
    "# === AdaBoost Classifier === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize model\n",
    "clf_ada = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.8\n",
    ")\n",
    "\n",
    "# Train model\n",
    "clf_ada.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ada = clf_ada.predict(X_test_class)\n",
    "\n",
    "# Evaluation\n",
    "acc_ada = accuracy_score(y_test_class, y_pred_ada)\n",
    "prec_ada = precision_score(y_test_class, y_pred_ada)\n",
    "rec_ada = recall_score(y_test_class, y_pred_ada)\n",
    "f1_ada = f1_score(y_test_class, y_pred_ada)\n",
    "\n",
    "print(\"AdaBoost Performance:\")\n",
    "print(\"----------------------\")\n",
    "print(\"Accuracy :\", acc_ada)\n",
    "print(\"Precision:\", prec_ada)\n",
    "print(\"Recall   :\", rec_ada)\n",
    "print(\"F1-score :\", f1_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes is a probabilistic classifier based on Bayes’ Theorem with an assumption of independence among features.\n",
    "\n",
    "Characteristics:\n",
    "- Extremely fast to train  \n",
    "- Works well even with high-dimensional data  \n",
    "- Performs surprisingly well when feature independence approximately holds  \n",
    "\n",
    "We will use **GaussianNB**, suitable for continuous numerical features.\n",
    "\n",
    "The model is evaluated using:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  \n",
    "\n",
    "All warnings are suppressed for clean output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:39.507062Z",
     "iopub.status.busy": "2025-11-30T06:26:39.506756Z",
     "iopub.status.idle": "2025-11-30T06:26:39.556410Z",
     "shell.execute_reply": "2025-11-30T06:26:39.555590Z",
     "shell.execute_reply.started": "2025-11-30T06:26:39.507035Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance:\n",
      "------------------------\n",
      "Accuracy : 0.8432274888786624\n",
      "Precision: 0.754017305315204\n",
      "Recall   : 0.9912252193695158\n",
      "F1-score : 0.8565009828699803\n"
     ]
    }
   ],
   "source": [
    "# === Naive Bayes Classifier (GaussianNB) === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize model\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "# Train model\n",
    "clf_nb.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nb = clf_nb.predict(X_test_class)\n",
    "\n",
    "# Evaluation\n",
    "acc_nb = accuracy_score(y_test_class, y_pred_nb)\n",
    "prec_nb = precision_score(y_test_class, y_pred_nb)\n",
    "rec_nb = recall_score(y_test_class, y_pred_nb)\n",
    "f1_nb = f1_score(y_test_class, y_pred_nb)\n",
    "\n",
    "print(\"Naive Bayes Performance:\")\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy :\", acc_nb)\n",
    "print(\"Precision:\", prec_nb)\n",
    "print(\"Recall   :\", rec_nb)\n",
    "print(\"F1-score :\", f1_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN) Classifier\n",
    "\n",
    "KNN is a simple distance-based classifier that assigns a label based on the majority class among the *k nearest neighbors* in feature space.\n",
    "\n",
    "Characteristics:\n",
    "- Non-parametric and easy to implement  \n",
    "- Can perform well when features are scaled appropriately  \n",
    "- Sensitive to feature scales and large datasets  \n",
    "\n",
    "For this project:\n",
    "- We use `KNeighborsClassifier`  \n",
    "- `n_neighbors = 5` (default, good starting point)  \n",
    "- Evaluation: Accuracy, Precision, Recall, F1-score  \n",
    "- Warnings suppressed for clean output  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:39.557443Z",
     "iopub.status.busy": "2025-11-30T06:26:39.557170Z",
     "iopub.status.idle": "2025-11-30T06:26:40.263708Z",
     "shell.execute_reply": "2025-11-30T06:26:40.262972Z",
     "shell.execute_reply.started": "2025-11-30T06:26:39.557417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Performance:\n",
      "---------------------------\n",
      "Accuracy : 0.876974996165056\n",
      "Precision: 0.826773915541511\n",
      "Recall   : 0.9353266168345792\n",
      "F1-score : 0.8777066178713022\n"
     ]
    }
   ],
   "source": [
    "# === K-Nearest Neighbors (KNN) Classifier === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize model\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train model\n",
    "clf_knn.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = clf_knn.predict(X_test_class)\n",
    "\n",
    "# Evaluation\n",
    "acc_knn = accuracy_score(y_test_class, y_pred_knn)\n",
    "prec_knn = precision_score(y_test_class, y_pred_knn)\n",
    "rec_knn = recall_score(y_test_class, y_pred_knn)\n",
    "f1_knn = f1_score(y_test_class, y_pred_knn)\n",
    "\n",
    "print(\"KNN Classifier Performance:\")\n",
    "print(\"---------------------------\")\n",
    "print(\"Accuracy :\", acc_knn)\n",
    "print(\"Precision:\", prec_knn)\n",
    "print(\"Recall   :\", rec_knn)\n",
    "print(\"F1-score :\", f1_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier for Pass/Fail Prediction\n",
    "\n",
    "XGBoost is one of the most powerful ensemble learning algorithms and is widely used in\n",
    "academic performance prediction research due to its ability to model nonlinear patterns\n",
    "and interactions between features.\n",
    "\n",
    "In this section, we train an `XGBClassifier` on the prepared dataset and evaluate its\n",
    "performance using:\n",
    "\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1-score  \n",
    "\n",
    "This model will later be compared with other classifiers in our comparison table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Performance:\n",
      "-------------------------------\n",
      "Accuracy : 0.9256020862095413\n",
      "Precision: 0.8932038834951457\n",
      "Recall   : 0.956776080597985\n",
      "F1-score : 0.923897693394006\n"
     ]
    }
   ],
   "source": [
    "# === XGBoost Classifier === #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "clf_xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf_xgb.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = clf_xgb.predict(X_test_class)\n",
    "\n",
    "# Evaluation metrics\n",
    "acc_xgb = accuracy_score(y_test_class, y_pred_xgb)\n",
    "prec_xgb = precision_score(y_test_class, y_pred_xgb)\n",
    "rec_xgb = recall_score(y_test_class, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test_class, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Classifier Performance:\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Accuracy :\", acc_xgb)\n",
    "print(\"Precision:\", prec_xgb)\n",
    "print(\"Recall   :\", rec_xgb)\n",
    "print(\"F1-score :\", f1_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Comparison\n",
    "\n",
    "After training all classification models, we now consolidate their performance metrics into a single comparison table.\n",
    "\n",
    "### Models Included:\n",
    "- Logistic Regression  \n",
    "- Random Forest  \n",
    "- SVM  \n",
    "- Gradient Boosting  \n",
    "- AdaBoost  \n",
    "- Naive Bayes  \n",
    "- K-Nearest Neighbors (KNN)  \n",
    "\n",
    "### Metrics Compared:\n",
    "- **Accuracy**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-score**\n",
    "\n",
    "Finally, models are **ranked based on Accuracy** to identify the best classifier for predicting student pass/fail outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:15:39.652680Z",
     "iopub.status.busy": "2025-11-30T07:15:39.652393Z",
     "iopub.status.idle": "2025-11-30T07:15:39.665145Z",
     "shell.execute_reply": "2025-11-30T07:15:39.664403Z",
     "shell.execute_reply.started": "2025-11-30T07:15:39.652659Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Model Comparison ===\n",
      "              Model  Accuracy  Precision   Recall  F1-score  Rank\n",
      " XGBoost Classifier  0.925602   0.893204 0.956776  0.923898   1.0\n",
      "      Random Forest  0.924222   0.894592 0.951576  0.922205   2.0\n",
      "  Gradient Boosting  0.920847   0.883039 0.959376  0.919626   3.0\n",
      "           AdaBoost  0.901825   0.857436 0.949951  0.901326   4.0\n",
      "Logistic Regression  0.890934   0.864673 0.911602  0.887518   5.0\n",
      "                SVM  0.885412   0.827984 0.955801  0.887313   6.0\n",
      "                KNN  0.876975   0.826774 0.935327  0.877707   7.0\n",
      "        Naive Bayes  0.843227   0.754017 0.991225  0.856501   8.0\n"
     ]
    }
   ],
   "source": [
    "# === Classification Model Comparison Table === #\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Collect all results\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Random Forest\",\n",
    "        \"SVM\",\n",
    "        \"Gradient Boosting\",\n",
    "        \"AdaBoost\",\n",
    "        \"Naive Bayes\",\n",
    "        \"KNN\",\n",
    "        \"XGBoost Classifier\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        acc_lr,\n",
    "        acc_rf,\n",
    "        acc_svm,\n",
    "        acc_gb,\n",
    "        acc_ada,\n",
    "        acc_nb,\n",
    "        acc_knn,\n",
    "        acc_xgb\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        prec_lr,\n",
    "        prec_rf,\n",
    "        prec_svm,\n",
    "        prec_gb,\n",
    "        prec_ada,\n",
    "        prec_nb,\n",
    "        prec_knn,\n",
    "        prec_xgb\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        rec_lr,\n",
    "        rec_rf,\n",
    "        rec_svm,\n",
    "        rec_gb,\n",
    "        rec_ada,\n",
    "        rec_nb,\n",
    "        rec_knn,\n",
    "        rec_xgb\n",
    "    ],\n",
    "    \"F1-score\": [\n",
    "        f1_lr,\n",
    "        f1_rf,\n",
    "        f1_svm,\n",
    "        f1_gb,\n",
    "        f1_ada,\n",
    "        f1_nb,\n",
    "        f1_knn,\n",
    "        f1_xgb\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Ranking by Accuracy\n",
    "comparison_df[\"Rank\"] = comparison_df[\"Accuracy\"].rank(ascending=False, method=\"dense\")\n",
    "\n",
    "# Sort by rank\n",
    "comparison_df = comparison_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "print(\"=== Classification Model Comparison ===\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏆 Best Classification Model Summary\n",
    "\n",
    "Based on the performance comparison of all seven classification algorithms, **Random Forest** achieved the **highest overall accuracy (92.73%)**, making it the best-performing model for predicting whether a student will pass or fail.\n",
    "\n",
    "### 🔍 Why Random Forest is the Best:\n",
    "- **Highest accuracy** among all models.\n",
    "- **Excellent F1-score**, showing strong balance between precision and recall.\n",
    "- **High recall** (95.65%) indicates the model effectively captures actual \"Pass\" students.\n",
    "- More robust to noise and feature interactions compared to simpler models.\n",
    "\n",
    "### 📌 Final Classification Ranking (by Accuracy):\n",
    "1. **Random Forest**  \n",
    "2. Gradient Boosting  \n",
    "3. AdaBoost  \n",
    "4. Logistic Regression  \n",
    "5. SVM  \n",
    "6. KNN  \n",
    "7. Naive Bayes  \n",
    "\n",
    "This concludes the classification model selection.  \n",
    "Next, we proceed to **Regression Modeling** for predicting student CGPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear Regression is the simplest regression model, used as a baseline to compare the performance of more advanced models later.\n",
    "\n",
    "It attempts to learn a straight-line relationship between the input features and the target variable (CGPA).  \n",
    "Although it may not capture complex patterns, it provides a useful reference point for evaluating whether more sophisticated models like Random Forest or Gradient Boosting actually add value.\n",
    "\n",
    "The following cell trains a Linear Regression model and evaluates it using:\n",
    "\n",
    "- MSE (Mean Squared Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- R² score (coefficient of determination)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:40.279196Z",
     "iopub.status.busy": "2025-11-30T06:26:40.278792Z",
     "iopub.status.idle": "2025-11-30T06:26:40.339006Z",
     "shell.execute_reply": "2025-11-30T06:26:40.337608Z",
     "shell.execute_reply.started": "2025-11-30T06:26:40.279175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "------------------------------\n",
      "MSE  : 0.20088325150604583\n",
      "RMSE : 0.44820001283583855\n",
      "R²   : 0.7945687252004903\n"
     ]
    }
   ],
   "source": [
    "# === Regression Model 1: Linear Regression === #\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize model\n",
    "reg_lr = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "reg_lr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr_reg = reg_lr.predict(X_test_reg)\n",
    "\n",
    "# Evaluation\n",
    "mse_lr = mean_squared_error(y_test_reg, y_pred_lr_reg)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test_reg, y_pred_lr_reg)\n",
    "\n",
    "print(\"Linear Regression Performance:\")\n",
    "print(\"------------------------------\")\n",
    "print(\"MSE  :\", mse_lr)\n",
    "print(\"RMSE :\", rmse_lr)\n",
    "print(\"R²   :\", r2_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression\n",
    "\n",
    "Random Forest Regressor is an ensemble model that builds many decision trees and averages their predictions.  \n",
    "It captures nonlinear relationships, handles noise well, and usually outperforms Linear Regression when the dataset is complex.\n",
    "\n",
    "We evaluate this model using:\n",
    "- MSE (Mean Squared Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- R² Score (explained variance)\n",
    "\n",
    "This model typically provides higher accuracy and lower error compared to Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:40.339862Z",
     "iopub.status.busy": "2025-11-30T06:26:40.339629Z",
     "iopub.status.idle": "2025-11-30T06:26:50.719017Z",
     "shell.execute_reply": "2025-11-30T06:26:50.718150Z",
     "shell.execute_reply.started": "2025-11-30T06:26:40.339841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Performance:\n",
      "------------------------------------\n",
      "MSE  : 0.1237849593495935\n",
      "RMSE : 0.3518308675338102\n",
      "R²   : 0.8734125328540535\n"
     ]
    }
   ],
   "source": [
    "# === Regression Model 2: Random Forest Regressor === #\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize model\n",
    "reg_rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "reg_rf.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = reg_rf.predict(X_test_reg)\n",
    "\n",
    "# Evaluation\n",
    "mse_rf = mean_squared_error(y_test_reg, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test_reg, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Regression Performance:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"MSE  :\", mse_rf)\n",
    "print(\"RMSE :\", rmse_rf)\n",
    "print(\"R²   :\", r2_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor\n",
    "\n",
    "Gradient Boosting is an ensemble technique that builds models sequentially, with each new model attempting to correct the errors of the previous one. It generally performs very well on structured/tabular datasets.\n",
    "\n",
    "Below is the model training and evaluation using MSE, RMSE, and R² metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:50.720476Z",
     "iopub.status.busy": "2025-11-30T06:26:50.719995Z",
     "iopub.status.idle": "2025-11-30T06:26:56.223991Z",
     "shell.execute_reply": "2025-11-30T06:26:56.222887Z",
     "shell.execute_reply.started": "2025-11-30T06:26:50.720454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Performance:\n",
      "----------------------------------------\n",
      "MSE  : 0.13158244954397486\n",
      "RMSE : 0.3627429524387412\n",
      "R²   : 0.8654385064538475\n"
     ]
    }
   ],
   "source": [
    "# === Gradient Boosting Regressor === #\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Train\n",
    "gbr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict\n",
    "y_pred_gb = gbr.predict(X_test_reg)\n",
    "\n",
    "# Evaluation\n",
    "mse_gb = mean_squared_error(y_test_reg, y_pred_gb)\n",
    "rmse_gb = np.sqrt(mse_gb)\n",
    "r2_gb = r2_score(y_test_reg, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting Regression Performance:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"MSE  :\", mse_gb)\n",
    "print(\"RMSE :\", rmse_gb)\n",
    "print(\"R²   :\", r2_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor\n",
    "\n",
    "AdaBoost trains a sequence of weak learners, where each new model focuses more on the samples the previous models predicted poorly. It is simple, efficient, and often performs well on structured data.\n",
    "\n",
    "Below is the training and evaluation of the AdaBoost Regressor using MSE, RMSE, and R² metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:56.225187Z",
     "iopub.status.busy": "2025-11-30T06:26:56.224923Z",
     "iopub.status.idle": "2025-11-30T06:26:57.265989Z",
     "shell.execute_reply": "2025-11-30T06:26:57.265232Z",
     "shell.execute_reply.started": "2025-11-30T06:26:56.225167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regression Performance:\n",
      "-------------------------------\n",
      "MSE  : 0.16284598730443794\n",
      "RMSE : 0.40354180366405407\n",
      "R²   : 0.8334671580774934\n"
     ]
    }
   ],
   "source": [
    "# === AdaBoost Regressor === #\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "ada_reg = AdaBoostRegressor()\n",
    "\n",
    "# Train\n",
    "ada_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict\n",
    "y_pred_ada = ada_reg.predict(X_test_reg)\n",
    "\n",
    "# Evaluation\n",
    "mse_ada = mean_squared_error(y_test_reg, y_pred_ada)\n",
    "rmse_ada = np.sqrt(mse_ada)\n",
    "r2_ada = r2_score(y_test_reg, y_pred_ada)\n",
    "\n",
    "print(\"AdaBoost Regression Performance:\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"MSE  :\", mse_ada)\n",
    "print(\"RMSE :\", rmse_ada)\n",
    "print(\"R²   :\", r2_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor (SVR)\n",
    "\n",
    "SVR attempts to fit the best possible line within a margin, making it robust to outliers. It often requires scaling for optimal performance but still works reasonably without it.\n",
    "\n",
    "Below is the SVR model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:26:57.267185Z",
     "iopub.status.busy": "2025-11-30T06:26:57.266851Z",
     "iopub.status.idle": "2025-11-30T06:27:26.672707Z",
     "shell.execute_reply": "2025-11-30T06:27:26.672000Z",
     "shell.execute_reply.started": "2025-11-30T06:26:57.267158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Regression Performance:\n",
      "---------------------------\n",
      "MSE  : 0.25728310461180726\n",
      "RMSE : 0.507230819856017\n",
      "R²   : 0.7368919719860842\n"
     ]
    }
   ],
   "source": [
    "# === SVR Regressor === #\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "y_pred_svr = svr.predict(X_test_reg)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test_reg, y_pred_svr)\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "r2_svr = r2_score(y_test_reg, y_pred_svr)\n",
    "\n",
    "print(\"SVR Regression Performance:\")\n",
    "print(\"---------------------------\")\n",
    "print(\"MSE  :\", mse_svr)\n",
    "print(\"RMSE :\", rmse_svr)\n",
    "print(\"R²   :\", r2_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regressor\n",
    "\n",
    "KNN predicts numerical values by averaging the outputs of the k-nearest data points. Performance heavily depends on feature scaling and neighborhood structure.\n",
    "\n",
    "Below is the performance evaluation for KNN Regressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:27:26.673894Z",
     "iopub.status.busy": "2025-11-30T06:27:26.673573Z",
     "iopub.status.idle": "2025-11-30T06:27:27.036560Z",
     "shell.execute_reply": "2025-11-30T06:27:27.035911Z",
     "shell.execute_reply.started": "2025-11-30T06:27:26.673868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression Performance:\n",
      "---------------------------\n",
      "MSE  : 0.2501242521859181\n",
      "RMSE : 0.5001242367511478\n",
      "R²   : 0.7442129017745376\n"
     ]
    }
   ],
   "source": [
    "# === KNN Regressor === #\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "knn_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "y_pred_knn = knn_reg.predict(X_test_reg)\n",
    "\n",
    "mse_knn = mean_squared_error(y_test_reg, y_pred_knn)\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "r2_knn = r2_score(y_test_reg, y_pred_knn)\n",
    "\n",
    "print(\"KNN Regression Performance:\")\n",
    "print(\"---------------------------\")\n",
    "print(\"MSE  :\", mse_knn)\n",
    "print(\"RMSE :\", rmse_knn)\n",
    "print(\"R²   :\", r2_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "\n",
    "Decision Trees split data into hierarchical regions and fit simple predictions inside them. They are easy to interpret but prone to overfitting.\n",
    "\n",
    "Below is the performance for the Decision Tree Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T06:27:27.037693Z",
     "iopub.status.busy": "2025-11-30T06:27:27.037381Z",
     "iopub.status.idle": "2025-11-30T06:27:27.261440Z",
     "shell.execute_reply": "2025-11-30T06:27:27.260618Z",
     "shell.execute_reply.started": "2025-11-30T06:27:27.037666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Performance:\n",
      "------------------------------------\n",
      "MSE  : 0.2299432428286547\n",
      "RMSE : 0.4795239752386263\n",
      "R²   : 0.7648508118438033\n"
     ]
    }
   ],
   "source": [
    "# === Decision Tree Regressor === #\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "\n",
    "dt_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "y_pred_dt = dt_reg.predict(X_test_reg)\n",
    "\n",
    "mse_dt = mean_squared_error(y_test_reg, y_pred_dt)\n",
    "rmse_dt = np.sqrt(mse_dt)\n",
    "r2_dt = r2_score(y_test_reg, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Regression Performance:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"MSE  :\", mse_dt)\n",
    "print(\"RMSE :\", rmse_dt)\n",
    "print(\"R²   :\", r2_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 XGBoost Regressor for CGPA Prediction\n",
    "\n",
    "XGBoost is well-suited for regression tasks involving complex interactions among features.\n",
    "Here, we train an `XGBRegressor` to predict the student's CGPA category (0–3 scale).\n",
    "\n",
    "We evaluate the model using:\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- R² Score\n",
    "\n",
    "This model will be compared with the other regression algorithms in the final comparison table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:10:53.657198Z",
     "iopub.status.busy": "2025-11-30T07:10:53.656518Z",
     "iopub.status.idle": "2025-11-30T07:10:54.453461Z",
     "shell.execute_reply": "2025-11-30T07:10:54.452547Z",
     "shell.execute_reply.started": "2025-11-30T07:10:53.657169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression Performance:\n",
      "--------------------------------\n",
      "MSE  : 0.11950205266475677\n",
      "RMSE : 0.34569068929428337\n",
      "R²   : 0.8777924180030823\n"
     ]
    }
   ],
   "source": [
    "# === XGBoost Regressor === #\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb_reg = xgb_reg.predict(X_test_reg)\n",
    "\n",
    "# Evaluation\n",
    "mse_xgb = mean_squared_error(y_test_reg, y_pred_xgb_reg)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(y_test_reg, y_pred_xgb_reg)\n",
    "\n",
    "print(\"XGBoost Regression Performance:\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"MSE  :\", mse_xgb)\n",
    "print(\"RMSE :\", rmse_xgb)\n",
    "print(\"R²   :\", r2_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Comparison\n",
    "\n",
    "After training all regression models, we evaluate them using the following metrics:\n",
    "\n",
    "- MSE (Mean Squared Error) – lower is better  \n",
    "- RMSE (Root Mean Squared Error) – lower is better  \n",
    "- R² Score – higher is better  \n",
    "\n",
    "The table below compares all regression models based on these evaluation metrics and ranks them according to their R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:10:15.025553Z",
     "iopub.status.busy": "2025-11-30T07:10:15.024923Z",
     "iopub.status.idle": "2025-11-30T07:10:15.037557Z",
     "shell.execute_reply": "2025-11-30T07:10:15.036643Z",
     "shell.execute_reply.started": "2025-11-30T07:10:15.025529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Regression Model Comparison ===\n",
      "                      Model      MSE     RMSE       R²  Rank\n",
      "          XGBoost Regressor 0.119502 0.345691 0.877792   1.0\n",
      "    Random Forest Regressor 0.123785 0.351831 0.873413   2.0\n",
      "Gradient Boosting Regressor 0.131582 0.362743 0.865439   3.0\n",
      "         AdaBoost Regressor 0.162846 0.403542 0.833467   4.0\n",
      "          Linear Regression 0.200883 0.448200 0.794569   5.0\n",
      "    Decision Tree Regressor 0.229943 0.479524 0.764851   6.0\n",
      "              KNN Regressor 0.250124 0.500124 0.744213   7.0\n",
      "                        SVR 0.257283 0.507231 0.736892   8.0\n"
     ]
    }
   ],
   "source": [
    "# === Final Regression Model Comparison (including XGBoost) === #\n",
    "\n",
    "reg_results_updated = {\n",
    "    \"Model\": [\n",
    "        \"XGBoost Regressor\",\n",
    "        \"Random Forest Regressor\",\n",
    "        \"Gradient Boosting Regressor\",\n",
    "        \"AdaBoost Regressor\",\n",
    "        \"Linear Regression\",\n",
    "        \"Decision Tree Regressor\",\n",
    "        \"KNN Regressor\",\n",
    "        \"SVR\"\n",
    "    ],\n",
    "    \"MSE\": [\n",
    "        mse_xgb,\n",
    "        mse_rf,\n",
    "        mse_gb,\n",
    "        mse_ada,\n",
    "        mse_lr,\n",
    "        mse_dt,\n",
    "        mse_knn,\n",
    "        mse_svr\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        rmse_xgb,\n",
    "        rmse_rf,\n",
    "        rmse_gb,\n",
    "        rmse_ada,\n",
    "        rmse_lr,\n",
    "        rmse_dt,\n",
    "        rmse_knn,\n",
    "        rmse_svr\n",
    "    ],\n",
    "    \"R²\": [\n",
    "        r2_xgb,\n",
    "        r2_rf,\n",
    "        r2_gb,\n",
    "        r2_ada,\n",
    "        r2_lr,\n",
    "        r2_dt,\n",
    "        r2_knn,\n",
    "        r2_svr\n",
    "    ]\n",
    "}\n",
    "\n",
    "reg_comparison_final = pd.DataFrame(reg_results_updated)\n",
    "\n",
    "# Rank models by R² Score (higher = better)\n",
    "reg_comparison_final[\"Rank\"] = reg_comparison_final[\"R²\"].rank(ascending=False, method=\"dense\")\n",
    "\n",
    "# Sort for display\n",
    "reg_comparison_final = reg_comparison_final.sort_values(by=\"R²\", ascending=False)\n",
    "\n",
    "print(\"=== Final Regression Model Comparison ===\")\n",
    "print(reg_comparison_final.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Building the Final Selected Models\n",
    "\n",
    "Based on model comparison results:\n",
    "\n",
    "- **XGBoost Classifier** achieved the highest accuracy, F1-score, and AUC for Pass/Fail prediction.\n",
    "- **XGBoost Regressor** achieved the lowest RMSE and highest R² score for CGPA prediction.\n",
    "\n",
    "In this step, we rebuild both models on the full training dataset so they can be saved\n",
    "and used in deployment (Flask/FastAPI backend).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:26:25.484670Z",
     "iopub.status.busy": "2025-11-30T07:26:25.484305Z",
     "iopub.status.idle": "2025-11-30T07:26:26.875280Z",
     "shell.execute_reply": "2025-11-30T07:26:26.874027Z",
     "shell.execute_reply.started": "2025-11-30T07:26:25.484636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final models successfully built.\n"
     ]
    }
   ],
   "source": [
    "# === FINAL MODEL BUILDING === #\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# -----------------------------\n",
    "# Final Classification Model\n",
    "# -----------------------------\n",
    "final_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "final_clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# -----------------------------\n",
    "# Final Regression Model\n",
    "# -----------------------------\n",
    "final_reg = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "final_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(\"Final models successfully built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Models and Preprocessing Objects\n",
    "\n",
    "To deploy the ML models in a Flask/FastAPI backend and integrate them into the web\n",
    "platform, we save the following components:\n",
    "\n",
    "- Final XGBoost Classifier (Pass/Fail Prediction)\n",
    "- Final XGBoost Regressor (CGPA Prediction)\n",
    "- Label Encoders for categorical features\n",
    "- List of feature columns used during model training\n",
    "\n",
    "These saved artifacts will later be loaded by the backend API to make predictions\n",
    "in real-time for students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:28:00.257626Z",
     "iopub.status.busy": "2025-11-30T07:28:00.256752Z",
     "iopub.status.idle": "2025-11-30T07:28:00.277411Z",
     "shell.execute_reply": "2025-11-30T07:28:00.276661Z",
     "shell.execute_reply.started": "2025-11-30T07:28:00.257595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model artifacts saved successfully at: ../models/student_performance_prediction.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Path where the model will be saved\n",
    "MODEL_PATH = \"../models/student_performance_prediction.pkl\"\n",
    "\n",
    "# Create a dictionary of objects to save\n",
    "model_artifacts = {\n",
    "    \"classifier\": final_clf,\n",
    "    \"regressor\": final_reg,\n",
    "    \"label_encoders\": label_encoders,\n",
    "    \"feature_columns\": feature_cols\n",
    "}\n",
    "\n",
    "# Save the dictionary as a pickle file\n",
    "with open(MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "\n",
    "print(f\"All model artifacts saved successfully at: {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 472058,
     "sourceId": 885513,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
